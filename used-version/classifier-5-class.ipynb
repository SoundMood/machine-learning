{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-12-05T12:35:28.117226Z",
     "iopub.status.busy": "2024-12-05T12:35:28.116837Z",
     "iopub.status.idle": "2024-12-05T12:35:28.124563Z",
     "shell.execute_reply": "2024-12-05T12:35:28.123691Z",
     "shell.execute_reply.started": "2024-12-05T12:35:28.117196Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob as gb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, LearningRateScheduler\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Configuration\n",
    "\n",
    "Setup for image size, batch size, and dataset paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_size = 100  # Image size \n",
    "batch_size = 64    # Batch size \n",
    "train_path = '../dataset\\\\raf-db-5class\\\\train'  # Training dataset path\n",
    "test_path = '../dataset\\\\raf-db-5class\\\\test'    # Testing dataset path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    "\n",
    "Augmentation for training (normalization, rotation, flip, etc.) and normalization for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T12:35:29.927713Z",
     "iopub.status.busy": "2024-12-05T12:35:29.926818Z",
     "iopub.status.idle": "2024-12-05T12:35:41.232653Z",
     "shell.execute_reply": "2024-12-05T12:35:41.231770Z",
     "shell.execute_reply.started": "2024-12-05T12:35:29.927667Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11268 images belonging to 5 classes.\n",
      "Found 2834 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# Augmentasi data untuk training (normalisasi, kecerahan, flip horizontal, rotasi, geser, zoom, dll)\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255, brightness_range=[0.9, 1.1], horizontal_flip=True, \n",
    "    rotation_range=40, width_shift_range=0.2, height_shift_range=0.2, \n",
    "    shear_range=0.2, zoom_range=0.2, channel_shift_range=10.0, fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Generator untuk data training\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_path, target_size=(images_size, images_size), batch_size=batch_size, \n",
    "    seed=32, shuffle=True, class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Augmentasi data untuk testing (normalisasi dan split validasi)\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255, validation_split=0.5\n",
    ")\n",
    "\n",
    "# Generator untuk data testing\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_path, target_size=(images_size, images_size), batch_size=batch_size, \n",
    "    shuffle=False, class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T12:35:49.780265Z",
     "iopub.status.busy": "2024-12-05T12:35:49.779435Z",
     "iopub.status.idle": "2024-12-05T12:35:49.786686Z",
     "shell.execute_reply": "2024-12-05T12:35:49.785840Z",
     "shell.execute_reply.started": "2024-12-05T12:35:49.780231Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train folder contains: ['angry', 'neutral', 'sad', 'surprised', 'happy']\n",
      "Test folder contains: ['angry', 'neutral', 'sad', 'surprised', 'happy']\n"
     ]
    }
   ],
   "source": [
    "# Cek struktur dataset\n",
    "print(f\"Train folder contains: {os.listdir(train_path)}\")\n",
    "print(f\"Test folder contains: {os.listdir(test_path)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks\n",
    "\n",
    "Callback settings for early stopping, learning rate reduction, and learning rate scheduling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T12:35:53.744975Z",
     "iopub.status.busy": "2024-12-05T12:35:53.744130Z",
     "iopub.status.idle": "2024-12-05T12:35:53.750081Z",
     "shell.execute_reply": "2024-12-05T12:35:53.749112Z",
     "shell.execute_reply.started": "2024-12-05T12:35:53.744939Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    min_delta=0.001,\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "learning_rate_reduce = ReduceLROnPlateau(\n",
    "    monitor='val_acc',  \n",
    "    patience=5,         \n",
    "    verbose=1,          \n",
    "    factor=0.5,          \n",
    "    min_lr=0.00001       \n",
    ")\n",
    "\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "learning_rate_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.01, \n",
    "    decay_steps=1000,            \n",
    "    decay_rate=0.5,            \n",
    ")\n",
    "\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "lr_callback = LearningRateScheduler(learning_rate_schedule)\n",
    "callback=[ lr_callback , learning_rate_reduce ,early_stopping ]\n",
    "\n",
    "def learning_rate_schedule(epoch):\n",
    "    initial_lr = 0.001\n",
    "    drop_factor = 0.5\n",
    "    epoch_drop = 10\n",
    "    return initial_lr * (drop_factor ** (epoch // epoch_drop))\n",
    "\n",
    "lr_callback = LearningRateScheduler(learning_rate_schedule)\n",
    "\n",
    "optimizer = Adam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom CNN Model\n",
    "\n",
    "A custom Convolutional Neural Network (CNN) model with multiple convolutional layers, batch normalization, max pooling, dropout, and regularization.\n",
    "\n",
    "- **Conv2D Layers**: Multiple convolutional layers with varying filters and kernel sizes.\n",
    "- **BatchNormalization**: Applied after each convolution layer for stable training.\n",
    "- **MaxPooling2D**: Pooling layers to downsample feature maps.\n",
    "- **Dropout**: Added after each layer to prevent overfitting.\n",
    "- **Dense Layers**: Fully connected layers with ReLU activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CustomCNN():\n",
    "    model= tf.keras.models.Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(images_size,images_size,3)))\n",
    "    model.add(Conv2D(64,(3,3), padding='same', activation='relu' ))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(128,(5,5), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "        \n",
    "    model.add(Conv2D(512,(3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(512,(3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(256,activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(512,activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(256,activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(512,activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T12:36:17.817178Z",
     "iopub.status.busy": "2024-12-05T12:36:17.816804Z",
     "iopub.status.idle": "2024-12-05T13:43:19.300840Z",
     "shell.execute_reply": "2024-12-05T13:43:19.299973Z",
     "shell.execute_reply.started": "2024-12-05T12:36:17.817149Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733402185.137700      91 service.cc:145] XLA service 0x7b4fd800a920 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1733402185.137776      91 service.cc:153]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  2/177\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.2227 - loss: 9.6221   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1733402204.227321      91 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m123/177\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 303ms/step - accuracy: 0.3275 - loss: 9.0076"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733402241.097856      89 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'input_reduce_select_fusion_4', 64 bytes spill stores, 64 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - accuracy: 0.3551 - loss: 8.5354\n",
      "Epoch 1: val_accuracy improved from -inf to 0.41814, saving model to 5kelasterbaek.keras\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 322ms/step - accuracy: 0.3555 - loss: 8.5269 - val_accuracy: 0.4181 - val_loss: 4.8979 - learning_rate: 0.0010\n",
      "Epoch 2/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.5657 - loss: 3.3506\n",
      "Epoch 2: val_accuracy improved from 0.41814 to 0.56457, saving model to 5kelasterbaek.keras\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 109ms/step - accuracy: 0.5658 - loss: 3.3474 - val_accuracy: 0.5646 - val_loss: 2.4157 - learning_rate: 0.0010\n",
      "Epoch 3/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.6266 - loss: 1.9200\n",
      "Epoch 3: val_accuracy improved from 0.56457 to 0.62562, saving model to 5kelasterbaek.keras\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 107ms/step - accuracy: 0.6267 - loss: 1.9190 - val_accuracy: 0.6256 - val_loss: 1.7343 - learning_rate: 0.0010\n",
      "Epoch 4/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.6456 - loss: 2.0513\n",
      "Epoch 4: val_accuracy improved from 0.62562 to 0.63867, saving model to 5kelasterbaek.keras\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 111ms/step - accuracy: 0.6457 - loss: 2.0512 - val_accuracy: 0.6387 - val_loss: 1.5870 - learning_rate: 0.0010\n",
      "Epoch 5/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7109 - loss: 1.3422\n",
      "Epoch 5: val_accuracy did not improve from 0.63867\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 105ms/step - accuracy: 0.7109 - loss: 1.3431 - val_accuracy: 0.6334 - val_loss: 1.9611 - learning_rate: 0.0010\n",
      "Epoch 6/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.7284 - loss: 1.4489\n",
      "Epoch 6: val_accuracy improved from 0.63867 to 0.73853, saving model to 5kelasterbaek.keras\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 114ms/step - accuracy: 0.7284 - loss: 1.4484 - val_accuracy: 0.7385 - val_loss: 1.2340 - learning_rate: 0.0010\n",
      "Epoch 7/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.6835 - loss: 2.8224\n",
      "Epoch 7: val_accuracy did not improve from 0.73853\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 114ms/step - accuracy: 0.6837 - loss: 2.8201 - val_accuracy: 0.7364 - val_loss: 1.4190 - learning_rate: 0.0010\n",
      "Epoch 8/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.7593 - loss: 1.2947\n",
      "Epoch 8: val_accuracy improved from 0.73853 to 0.74241, saving model to 5kelasterbaek.keras\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 110ms/step - accuracy: 0.7593 - loss: 1.2945 - val_accuracy: 0.7424 - val_loss: 1.1737 - learning_rate: 0.0010\n",
      "Epoch 9/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.7687 - loss: 1.1411\n",
      "Epoch 9: val_accuracy improved from 0.74241 to 0.75406, saving model to 5kelasterbaek.keras\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 112ms/step - accuracy: 0.7687 - loss: 1.1417 - val_accuracy: 0.7541 - val_loss: 1.4469 - learning_rate: 0.0010\n",
      "Epoch 10/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.7640 - loss: 1.2419\n",
      "Epoch 10: val_accuracy improved from 0.75406 to 0.76112, saving model to 5kelasterbaek.keras\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 111ms/step - accuracy: 0.7640 - loss: 1.2418 - val_accuracy: 0.7611 - val_loss: 1.1181 - learning_rate: 0.0010\n",
      "Epoch 11/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.7897 - loss: 0.9939\n",
      "Epoch 11: val_accuracy improved from 0.76112 to 0.77841, saving model to 5kelasterbaek.keras\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 110ms/step - accuracy: 0.7898 - loss: 0.9937 - val_accuracy: 0.7784 - val_loss: 0.9758 - learning_rate: 5.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.8080 - loss: 0.9268\n",
      "Epoch 12: val_accuracy improved from 0.77841 to 0.80593, saving model to 5kelasterbaek.keras\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 111ms/step - accuracy: 0.8080 - loss: 0.9269 - val_accuracy: 0.8059 - val_loss: 0.8738 - learning_rate: 5.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.8180 - loss: 0.8639\n",
      "Epoch 13: val_accuracy improved from 0.80593 to 0.81863, saving model to 5kelasterbaek.keras\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 113ms/step - accuracy: 0.8179 - loss: 0.8642 - val_accuracy: 0.8186 - val_loss: 0.9380 - learning_rate: 5.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8260 - loss: 0.8826\n",
      "Epoch 14: val_accuracy did not improve from 0.81863\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 108ms/step - accuracy: 0.8260 - loss: 0.8827 - val_accuracy: 0.7463 - val_loss: 1.1285 - learning_rate: 5.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.8167 - loss: 0.9886\n",
      "Epoch 15: val_accuracy did not improve from 0.81863\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 109ms/step - accuracy: 0.8167 - loss: 0.9883 - val_accuracy: 0.8144 - val_loss: 0.9057 - learning_rate: 5.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.8247 - loss: 0.9540\n",
      "Epoch 16: val_accuracy did not improve from 0.81863\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 109ms/step - accuracy: 0.8247 - loss: 0.9545 - val_accuracy: 0.8105 - val_loss: 1.0756 - learning_rate: 5.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.8212 - loss: 1.0056\n",
      "Epoch 17: val_accuracy did not improve from 0.81863\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 107ms/step - accuracy: 0.8212 - loss: 1.0053 - val_accuracy: 0.8165 - val_loss: 0.9157 - learning_rate: 5.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8721 - loss: 0.6760\n",
      "Epoch 23: val_accuracy improved from 0.83380 to 0.83698, saving model to 5kelasterbaek.keras\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 108ms/step - accuracy: 0.8721 - loss: 0.6761 - val_accuracy: 0.8370 - val_loss: 0.7876 - learning_rate: 2.5000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.8744 - loss: 0.6712\n",
      "Epoch 24: val_accuracy did not improve from 0.83698\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 106ms/step - accuracy: 0.8744 - loss: 0.6712 - val_accuracy: 0.8335 - val_loss: 0.7577 - learning_rate: 2.5000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8747 - loss: 0.6460\n",
      "Epoch 25: val_accuracy did not improve from 0.83698\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 106ms/step - accuracy: 0.8747 - loss: 0.6461 - val_accuracy: 0.8282 - val_loss: 0.8027 - learning_rate: 2.5000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.8394 - loss: 0.9683\n",
      "Epoch 26: val_accuracy improved from 0.83698 to 0.84510, saving model to 5kelasterbaek.keras\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 110ms/step - accuracy: 0.8394 - loss: 0.9684 - val_accuracy: 0.8451 - val_loss: 0.9073 - learning_rate: 2.5000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.8752 - loss: 0.7638\n",
      "Epoch 27: val_accuracy did not improve from 0.84510\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 110ms/step - accuracy: 0.8752 - loss: 0.7635 - val_accuracy: 0.8377 - val_loss: 0.7576 - learning_rate: 2.5000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.8909 - loss: 0.6131\n",
      "Epoch 28: val_accuracy improved from 0.84510 to 0.85145, saving model to 5kelasterbaek.keras\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 112ms/step - accuracy: 0.8908 - loss: 0.6131 - val_accuracy: 0.8514 - val_loss: 0.7306 - learning_rate: 2.5000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.8818 - loss: 0.6781\n",
      "Epoch 29: val_accuracy did not improve from 0.85145\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 107ms/step - accuracy: 0.8818 - loss: 0.6786 - val_accuracy: 0.8405 - val_loss: 0.8917 - learning_rate: 2.5000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8818 - loss: 0.7246\n",
      "Epoch 30: val_accuracy did not improve from 0.85145\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 107ms/step - accuracy: 0.8818 - loss: 0.7245 - val_accuracy: 0.8500 - val_loss: 0.7597 - learning_rate: 2.5000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9071 - loss: 0.5983\n",
      "Epoch 31: val_accuracy improved from 0.85145 to 0.85356, saving model to 5kelasterbaek.keras\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 108ms/step - accuracy: 0.9071 - loss: 0.5983 - val_accuracy: 0.8536 - val_loss: 0.7088 - learning_rate: 1.2500e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9125 - loss: 0.5274\n",
      "Epoch 32: val_accuracy improved from 0.85356 to 0.86203, saving model to 5kelasterbaek.keras\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 108ms/step - accuracy: 0.9124 - loss: 0.5274 - val_accuracy: 0.8620 - val_loss: 0.6464 - learning_rate: 1.2500e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.9131 - loss: 0.4680\n",
      "Epoch 33: val_accuracy did not improve from 0.86203\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 108ms/step - accuracy: 0.9131 - loss: 0.4680 - val_accuracy: 0.8564 - val_loss: 0.6363 - learning_rate: 1.2500e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.9224 - loss: 0.4500\n",
      "Epoch 34: val_accuracy improved from 0.86203 to 0.86803, saving model to 5kelasterbaek.keras\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 113ms/step - accuracy: 0.9224 - loss: 0.4500 - val_accuracy: 0.8680 - val_loss: 0.6115 - learning_rate: 1.2500e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9278 - loss: 0.4162\n",
      "Epoch 35: val_accuracy did not improve from 0.86803\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 111ms/step - accuracy: 0.9277 - loss: 0.4162 - val_accuracy: 0.8603 - val_loss: 0.6312 - learning_rate: 1.2500e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.9249 - loss: 0.4203\n",
      "Epoch 36: val_accuracy did not improve from 0.86803\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 144ms/step - accuracy: 0.9249 - loss: 0.4204 - val_accuracy: 0.8564 - val_loss: 0.6470 - learning_rate: 1.2500e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.9290 - loss: 0.4223\n",
      "Epoch 37: val_accuracy did not improve from 0.86803\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 124ms/step - accuracy: 0.9289 - loss: 0.4224 - val_accuracy: 0.8560 - val_loss: 0.6591 - learning_rate: 1.2500e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9194 - loss: 0.4930\n",
      "Epoch 38: val_accuracy did not improve from 0.86803\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 107ms/step - accuracy: 0.9193 - loss: 0.4934 - val_accuracy: 0.8514 - val_loss: 0.7961 - learning_rate: 1.2500e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9314 - loss: 0.5490\n",
      "Epoch 39: val_accuracy did not improve from 0.86803\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 108ms/step - accuracy: 0.9313 - loss: 0.5490 - val_accuracy: 0.8589 - val_loss: 0.7249 - learning_rate: 1.2500e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.9261 - loss: 0.4949\n",
      "Epoch 40: val_accuracy did not improve from 0.86803\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 109ms/step - accuracy: 0.9261 - loss: 0.4949 - val_accuracy: 0.8627 - val_loss: 0.6765 - learning_rate: 1.2500e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.9383 - loss: 0.4351\n",
      "Epoch 41: val_accuracy improved from 0.86803 to 0.86980, saving model to 5kelasterbaek.keras\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 114ms/step - accuracy: 0.9383 - loss: 0.4351 - val_accuracy: 0.8698 - val_loss: 0.6400 - learning_rate: 6.2500e-05\n",
      "Epoch 42/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.9469 - loss: 0.3847\n",
      "Epoch 42: val_accuracy did not improve from 0.86980\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 109ms/step - accuracy: 0.9469 - loss: 0.3847 - val_accuracy: 0.8620 - val_loss: 0.6368 - learning_rate: 6.2500e-05\n",
      "Epoch 43/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.9444 - loss: 0.3753\n",
      "Epoch 43: val_accuracy improved from 0.86980 to 0.87191, saving model to 5kelasterbaek.keras\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 115ms/step - accuracy: 0.9445 - loss: 0.3752 - val_accuracy: 0.8719 - val_loss: 0.6066 - learning_rate: 6.2500e-05\n",
      "Epoch 44/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.9524 - loss: 0.3408\n",
      "Epoch 44: val_accuracy did not improve from 0.87191\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 112ms/step - accuracy: 0.9524 - loss: 0.3408 - val_accuracy: 0.8691 - val_loss: 0.6046 - learning_rate: 6.2500e-05\n",
      "Epoch 45/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.9484 - loss: 0.3347\n",
      "Epoch 45: val_accuracy did not improve from 0.87191\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 111ms/step - accuracy: 0.9484 - loss: 0.3347 - val_accuracy: 0.8698 - val_loss: 0.6198 - learning_rate: 6.2500e-05\n",
      "Epoch 46/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.9562 - loss: 0.3140\n",
      "Epoch 46: val_accuracy did not improve from 0.87191\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 118ms/step - accuracy: 0.9562 - loss: 0.3140 - val_accuracy: 0.8701 - val_loss: 0.5985 - learning_rate: 6.2500e-05\n",
      "Epoch 47/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.9554 - loss: 0.3088\n",
      "Epoch 47: val_accuracy did not improve from 0.87191\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 114ms/step - accuracy: 0.9554 - loss: 0.3088 - val_accuracy: 0.8610 - val_loss: 0.6256 - learning_rate: 6.2500e-05\n",
      "Epoch 48/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.9499 - loss: 0.3203\n",
      "Epoch 48: val_accuracy did not improve from 0.87191\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 114ms/step - accuracy: 0.9499 - loss: 0.3204 - val_accuracy: 0.8571 - val_loss: 0.6518 - learning_rate: 6.2500e-05\n",
      "Epoch 49/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.9490 - loss: 0.3314\n",
      "Epoch 49: val_accuracy did not improve from 0.87191\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 112ms/step - accuracy: 0.9490 - loss: 0.3314 - val_accuracy: 0.8631 - val_loss: 0.6092 - learning_rate: 6.2500e-05\n",
      "Epoch 50/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.9541 - loss: 0.3165\n",
      "Epoch 50: val_accuracy improved from 0.87191 to 0.87227, saving model to 5kelasterbaek.keras\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 112ms/step - accuracy: 0.9540 - loss: 0.3166 - val_accuracy: 0.8723 - val_loss: 0.6097 - learning_rate: 6.2500e-05\n",
      "Epoch 51/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9601 - loss: 0.3248\n",
      "Epoch 51: val_accuracy improved from 0.87227 to 0.87579, saving model to 5kelasterbaek.keras\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 110ms/step - accuracy: 0.9601 - loss: 0.3248 - val_accuracy: 0.8758 - val_loss: 0.5873 - learning_rate: 3.1250e-05\n",
      "Epoch 52/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.9623 - loss: 0.3017\n",
      "Epoch 52: val_accuracy did not improve from 0.87579\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 111ms/step - accuracy: 0.9623 - loss: 0.3017 - val_accuracy: 0.8758 - val_loss: 0.5993 - learning_rate: 3.1250e-05\n",
      "Epoch 53/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.9590 - loss: 0.3066\n",
      "Epoch 53: val_accuracy improved from 0.87579 to 0.88144, saving model to 5kelasterbaek.keras\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 111ms/step - accuracy: 0.9590 - loss: 0.3065 - val_accuracy: 0.8814 - val_loss: 0.5898 - learning_rate: 3.1250e-05\n",
      "Epoch 54/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.9658 - loss: 0.2879\n",
      "Epoch 54: val_accuracy did not improve from 0.88144\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 108ms/step - accuracy: 0.9658 - loss: 0.2879 - val_accuracy: 0.8793 - val_loss: 0.5846 - learning_rate: 3.1250e-05\n",
      "Epoch 55/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.9676 - loss: 0.2760\n",
      "Epoch 55: val_accuracy did not improve from 0.88144\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 109ms/step - accuracy: 0.9676 - loss: 0.2760 - val_accuracy: 0.8811 - val_loss: 0.5721 - learning_rate: 3.1250e-05\n",
      "Epoch 56/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9692 - loss: 0.2635\n",
      "Epoch 56: val_accuracy did not improve from 0.88144\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 105ms/step - accuracy: 0.9692 - loss: 0.2635 - val_accuracy: 0.8761 - val_loss: 0.5780 - learning_rate: 3.1250e-05\n",
      "Epoch 57/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.9664 - loss: 0.2624\n",
      "Epoch 57: val_accuracy did not improve from 0.88144\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 107ms/step - accuracy: 0.9664 - loss: 0.2623 - val_accuracy: 0.8793 - val_loss: 0.5815 - learning_rate: 3.1250e-05\n",
      "Epoch 58/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.9741 - loss: 0.2445\n",
      "Epoch 58: val_accuracy did not improve from 0.88144\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 112ms/step - accuracy: 0.9741 - loss: 0.2445 - val_accuracy: 0.8804 - val_loss: 0.5754 - learning_rate: 3.1250e-05\n",
      "Epoch 59/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.9709 - loss: 0.2452\n",
      "Epoch 59: val_accuracy did not improve from 0.88144\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 112ms/step - accuracy: 0.9709 - loss: 0.2452 - val_accuracy: 0.8776 - val_loss: 0.5865 - learning_rate: 3.1250e-05\n",
      "Epoch 60/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.9633 - loss: 0.2670\n",
      "Epoch 60: val_accuracy did not improve from 0.88144\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 109ms/step - accuracy: 0.9633 - loss: 0.2670 - val_accuracy: 0.8726 - val_loss: 0.5924 - learning_rate: 3.1250e-05\n",
      "Epoch 61/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.9684 - loss: 0.2599\n",
      "Epoch 61: val_accuracy did not improve from 0.88144\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 107ms/step - accuracy: 0.9684 - loss: 0.2599 - val_accuracy: 0.8733 - val_loss: 0.5883 - learning_rate: 1.5625e-05\n",
      "Epoch 62/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9726 - loss: 0.2440\n",
      "Epoch 62: val_accuracy did not improve from 0.88144\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 105ms/step - accuracy: 0.9726 - loss: 0.2440 - val_accuracy: 0.8737 - val_loss: 0.5876 - learning_rate: 1.5625e-05\n",
      "Epoch 63/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.9686 - loss: 0.2467\n",
      "Epoch 63: val_accuracy did not improve from 0.88144\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 110ms/step - accuracy: 0.9686 - loss: 0.2467 - val_accuracy: 0.8783 - val_loss: 0.5943 - learning_rate: 1.5625e-05\n",
      "Epoch 64/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.9687 - loss: 0.2504\n",
      "Epoch 64: val_accuracy did not improve from 0.88144\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 108ms/step - accuracy: 0.9687 - loss: 0.2504 - val_accuracy: 0.8754 - val_loss: 0.5835 - learning_rate: 1.5625e-05\n",
      "Epoch 65/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9737 - loss: 0.2397\n",
      "Epoch 65: val_accuracy did not improve from 0.88144\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 107ms/step - accuracy: 0.9737 - loss: 0.2396 - val_accuracy: 0.8740 - val_loss: 0.5809 - learning_rate: 1.5625e-05\n",
      "Epoch 66/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.9711 - loss: 0.2384\n",
      "Epoch 66: val_accuracy did not improve from 0.88144\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 108ms/step - accuracy: 0.9711 - loss: 0.2384 - val_accuracy: 0.8772 - val_loss: 0.5792 - learning_rate: 1.5625e-05\n",
      "Epoch 67/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.9785 - loss: 0.2246\n",
      "Epoch 67: val_accuracy did not improve from 0.88144\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 110ms/step - accuracy: 0.9785 - loss: 0.2247 - val_accuracy: 0.8790 - val_loss: 0.5807 - learning_rate: 1.5625e-05\n",
      "Epoch 68/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.9778 - loss: 0.2211\n",
      "Epoch 68: val_accuracy did not improve from 0.88144\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 111ms/step - accuracy: 0.9778 - loss: 0.2211 - val_accuracy: 0.8737 - val_loss: 0.6038 - learning_rate: 1.5625e-05\n",
      "Epoch 69/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.9747 - loss: 0.2253\n",
      "Epoch 69: val_accuracy did not improve from 0.88144\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 111ms/step - accuracy: 0.9747 - loss: 0.2253 - val_accuracy: 0.8716 - val_loss: 0.6001 - learning_rate: 1.5625e-05\n",
      "Epoch 70/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.9735 - loss: 0.2267\n",
      "Epoch 70: val_accuracy did not improve from 0.88144\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 107ms/step - accuracy: 0.9735 - loss: 0.2267 - val_accuracy: 0.8790 - val_loss: 0.5766 - learning_rate: 1.5625e-05\n",
      "Epoch 71/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9752 - loss: 0.2176\n",
      "Epoch 71: val_accuracy did not improve from 0.88144\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 107ms/step - accuracy: 0.9753 - loss: 0.2176 - val_accuracy: 0.8751 - val_loss: 0.5759 - learning_rate: 7.8125e-06\n",
      "Epoch 72/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9823 - loss: 0.2063\n",
      "Epoch 72: val_accuracy did not improve from 0.88144\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 104ms/step - accuracy: 0.9823 - loss: 0.2063 - val_accuracy: 0.8772 - val_loss: 0.5766 - learning_rate: 7.8125e-06\n",
      "Epoch 73/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9776 - loss: 0.2134\n",
      "Epoch 73: val_accuracy did not improve from 0.88144\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 107ms/step - accuracy: 0.9776 - loss: 0.2134 - val_accuracy: 0.8744 - val_loss: 0.5760 - learning_rate: 7.8125e-06\n",
      "Epoch 74/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.9808 - loss: 0.2041\n",
      "Epoch 74: val_accuracy did not improve from 0.88144\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 108ms/step - accuracy: 0.9808 - loss: 0.2041 - val_accuracy: 0.8754 - val_loss: 0.5808 - learning_rate: 7.8125e-06\n",
      "Epoch 75/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9785 - loss: 0.2110\n",
      "Epoch 75: val_accuracy did not improve from 0.88144\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 108ms/step - accuracy: 0.9785 - loss: 0.2110 - val_accuracy: 0.8769 - val_loss: 0.5717 - learning_rate: 7.8125e-06\n",
      "Epoch 76/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.9825 - loss: 0.2035\n",
      "Epoch 76: val_accuracy did not improve from 0.88144\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 111ms/step - accuracy: 0.9825 - loss: 0.2035 - val_accuracy: 0.8779 - val_loss: 0.5739 - learning_rate: 7.8125e-06\n",
      "Epoch 77/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.9812 - loss: 0.2028\n",
      "Epoch 77: val_accuracy did not improve from 0.88144\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 108ms/step - accuracy: 0.9812 - loss: 0.2028 - val_accuracy: 0.8783 - val_loss: 0.5735 - learning_rate: 7.8125e-06\n",
      "Epoch 78/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9805 - loss: 0.2017\n",
      "Epoch 78: val_accuracy did not improve from 0.88144\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 106ms/step - accuracy: 0.9805 - loss: 0.2017 - val_accuracy: 0.8793 - val_loss: 0.5739 - learning_rate: 7.8125e-06\n",
      "Epoch 79/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.9846 - loss: 0.1964\n",
      "Epoch 79: val_accuracy did not improve from 0.88144\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 109ms/step - accuracy: 0.9846 - loss: 0.1964 - val_accuracy: 0.8779 - val_loss: 0.5733 - learning_rate: 7.8125e-06\n",
      "Epoch 80/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9805 - loss: 0.1997\n",
      "Epoch 80: val_accuracy did not improve from 0.88144\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 105ms/step - accuracy: 0.9805 - loss: 0.1997 - val_accuracy: 0.8786 - val_loss: 0.5688 - learning_rate: 7.8125e-06\n",
      "Epoch 81/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9848 - loss: 0.1904\n",
      "Epoch 81: val_accuracy did not improve from 0.88144\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 107ms/step - accuracy: 0.9848 - loss: 0.1904 - val_accuracy: 0.8776 - val_loss: 0.5710 - learning_rate: 3.9063e-06\n",
      "Epoch 82/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.9817 - loss: 0.1976\n",
      "Epoch 82: val_accuracy did not improve from 0.88144\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 112ms/step - accuracy: 0.9817 - loss: 0.1976 - val_accuracy: 0.8790 - val_loss: 0.5715 - learning_rate: 3.9063e-06\n",
      "Epoch 83/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.9851 - loss: 0.1909\n",
      "Epoch 83: val_accuracy did not improve from 0.88144\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 111ms/step - accuracy: 0.9851 - loss: 0.1909 - val_accuracy: 0.8793 - val_loss: 0.5712 - learning_rate: 3.9063e-06\n",
      "Epoch 84/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9840 - loss: 0.1908\n",
      "Epoch 84: val_accuracy did not improve from 0.88144\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 105ms/step - accuracy: 0.9840 - loss: 0.1908 - val_accuracy: 0.8811 - val_loss: 0.5690 - learning_rate: 3.9063e-06\n",
      "Epoch 85/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.9834 - loss: 0.1898\n",
      "Epoch 85: val_accuracy did not improve from 0.88144\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 107ms/step - accuracy: 0.9834 - loss: 0.1898 - val_accuracy: 0.8807 - val_loss: 0.5698 - learning_rate: 3.9063e-06\n",
      "Epoch 86/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9846 - loss: 0.1873\n",
      "Epoch 86: val_accuracy did not improve from 0.88144\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 104ms/step - accuracy: 0.9846 - loss: 0.1873 - val_accuracy: 0.8776 - val_loss: 0.5703 - learning_rate: 3.9063e-06\n",
      "Epoch 87/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.9836 - loss: 0.1872\n",
      "Epoch 87: val_accuracy did not improve from 0.88144\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 110ms/step - accuracy: 0.9836 - loss: 0.1872 - val_accuracy: 0.8804 - val_loss: 0.5678 - learning_rate: 3.9063e-06\n",
      "Epoch 88/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.9838 - loss: 0.1854\n",
      "Epoch 88: val_accuracy did not improve from 0.88144\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 111ms/step - accuracy: 0.9838 - loss: 0.1854 - val_accuracy: 0.8779 - val_loss: 0.5682 - learning_rate: 3.9063e-06\n",
      "Epoch 89/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.9862 - loss: 0.1814\n",
      "Epoch 89: val_accuracy did not improve from 0.88144\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 109ms/step - accuracy: 0.9862 - loss: 0.1814 - val_accuracy: 0.8800 - val_loss: 0.5688 - learning_rate: 3.9063e-06\n",
      "Epoch 90/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9855 - loss: 0.1833\n",
      "Epoch 90: val_accuracy did not improve from 0.88144\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 106ms/step - accuracy: 0.9855 - loss: 0.1833 - val_accuracy: 0.8772 - val_loss: 0.5691 - learning_rate: 3.9063e-06\n",
      "Epoch 91/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9861 - loss: 0.1824\n",
      "Epoch 91: val_accuracy did not improve from 0.88144\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 106ms/step - accuracy: 0.9861 - loss: 0.1824 - val_accuracy: 0.8790 - val_loss: 0.5681 - learning_rate: 1.9531e-06\n",
      "Epoch 92/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9852 - loss: 0.1834\n",
      "Epoch 92: val_accuracy did not improve from 0.88144\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 105ms/step - accuracy: 0.9852 - loss: 0.1833 - val_accuracy: 0.8793 - val_loss: 0.5678 - learning_rate: 1.9531e-06\n",
      "Epoch 93/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9835 - loss: 0.1850\n",
      "Epoch 93: val_accuracy did not improve from 0.88144\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 105ms/step - accuracy: 0.9835 - loss: 0.1850 - val_accuracy: 0.8800 - val_loss: 0.5669 - learning_rate: 1.9531e-06\n",
      "Epoch 94/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9877 - loss: 0.1774\n",
      "Epoch 94: val_accuracy did not improve from 0.88144\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 106ms/step - accuracy: 0.9877 - loss: 0.1774 - val_accuracy: 0.8811 - val_loss: 0.5638 - learning_rate: 1.9531e-06\n",
      "Epoch 95/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9859 - loss: 0.1826\n",
      "Epoch 95: val_accuracy did not improve from 0.88144\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 103ms/step - accuracy: 0.9859 - loss: 0.1827 - val_accuracy: 0.8790 - val_loss: 0.5669 - learning_rate: 1.9531e-06\n",
      "Epoch 96/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9851 - loss: 0.1816\n",
      "Epoch 96: val_accuracy did not improve from 0.88144\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 105ms/step - accuracy: 0.9851 - loss: 0.1816 - val_accuracy: 0.8793 - val_loss: 0.5657 - learning_rate: 1.9531e-06\n",
      "Epoch 97/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.9841 - loss: 0.1833\n",
      "Epoch 97: val_accuracy improved from 0.88144 to 0.88215, saving model to 5kelasterbaek.keras\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 109ms/step - accuracy: 0.9841 - loss: 0.1832 - val_accuracy: 0.8821 - val_loss: 0.5658 - learning_rate: 1.9531e-06\n",
      "Epoch 98/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9860 - loss: 0.1783\n",
      "Epoch 98: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 104ms/step - accuracy: 0.9860 - loss: 0.1783 - val_accuracy: 0.8818 - val_loss: 0.5649 - learning_rate: 1.9531e-06\n",
      "Epoch 99/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.9876 - loss: 0.1753\n",
      "Epoch 99: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 108ms/step - accuracy: 0.9876 - loss: 0.1753 - val_accuracy: 0.8800 - val_loss: 0.5662 - learning_rate: 1.9531e-06\n",
      "Epoch 100/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.9847 - loss: 0.1808\n",
      "Epoch 100: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 111ms/step - accuracy: 0.9847 - loss: 0.1808 - val_accuracy: 0.8800 - val_loss: 0.5639 - learning_rate: 1.9531e-06\n",
      "Epoch 101/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.9859 - loss: 0.1786\n",
      "Epoch 101: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 108ms/step - accuracy: 0.9858 - loss: 0.1786 - val_accuracy: 0.8779 - val_loss: 0.5659 - learning_rate: 9.7656e-07\n",
      "Epoch 102/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9856 - loss: 0.1789\n",
      "Epoch 102: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 106ms/step - accuracy: 0.9856 - loss: 0.1789 - val_accuracy: 0.8786 - val_loss: 0.5650 - learning_rate: 9.7656e-07\n",
      "Epoch 103/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.9857 - loss: 0.1772\n",
      "Epoch 103: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 108ms/step - accuracy: 0.9857 - loss: 0.1772 - val_accuracy: 0.8797 - val_loss: 0.5637 - learning_rate: 9.7656e-07\n",
      "Epoch 104/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9831 - loss: 0.1820\n",
      "Epoch 104: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 104ms/step - accuracy: 0.9831 - loss: 0.1820 - val_accuracy: 0.8783 - val_loss: 0.5654 - learning_rate: 9.7656e-07\n",
      "Epoch 105/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.9876 - loss: 0.1752\n",
      "Epoch 105: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 107ms/step - accuracy: 0.9876 - loss: 0.1752 - val_accuracy: 0.8783 - val_loss: 0.5640 - learning_rate: 9.7656e-07\n",
      "Epoch 106/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9853 - loss: 0.1778\n",
      "Epoch 106: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 104ms/step - accuracy: 0.9853 - loss: 0.1778 - val_accuracy: 0.8779 - val_loss: 0.5644 - learning_rate: 9.7656e-07\n",
      "Epoch 107/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9830 - loss: 0.1805\n",
      "Epoch 107: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 104ms/step - accuracy: 0.9830 - loss: 0.1805 - val_accuracy: 0.8783 - val_loss: 0.5630 - learning_rate: 9.7656e-07\n",
      "Epoch 108/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.9847 - loss: 0.1797\n",
      "Epoch 108: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 113ms/step - accuracy: 0.9847 - loss: 0.1797 - val_accuracy: 0.8769 - val_loss: 0.5642 - learning_rate: 9.7656e-07\n",
      "Epoch 109/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.9854 - loss: 0.1773\n",
      "Epoch 109: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 113ms/step - accuracy: 0.9854 - loss: 0.1773 - val_accuracy: 0.8786 - val_loss: 0.5634 - learning_rate: 9.7656e-07\n",
      "Epoch 110/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.9855 - loss: 0.1782\n",
      "Epoch 110: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 109ms/step - accuracy: 0.9855 - loss: 0.1782 - val_accuracy: 0.8790 - val_loss: 0.5643 - learning_rate: 9.7656e-07\n",
      "Epoch 111/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.9869 - loss: 0.1771\n",
      "Epoch 111: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 109ms/step - accuracy: 0.9869 - loss: 0.1771 - val_accuracy: 0.8793 - val_loss: 0.5630 - learning_rate: 4.8828e-07\n",
      "Epoch 112/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.9861 - loss: 0.1771\n",
      "Epoch 112: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 111ms/step - accuracy: 0.9860 - loss: 0.1771 - val_accuracy: 0.8797 - val_loss: 0.5626 - learning_rate: 4.8828e-07\n",
      "Epoch 113/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.9865 - loss: 0.1754\n",
      "Epoch 113: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 107ms/step - accuracy: 0.9865 - loss: 0.1754 - val_accuracy: 0.8793 - val_loss: 0.5629 - learning_rate: 4.8828e-07\n",
      "Epoch 114/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9879 - loss: 0.1731\n",
      "Epoch 114: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 106ms/step - accuracy: 0.9879 - loss: 0.1731 - val_accuracy: 0.8793 - val_loss: 0.5634 - learning_rate: 4.8828e-07\n",
      "Epoch 115/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9855 - loss: 0.1768\n",
      "Epoch 115: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 108ms/step - accuracy: 0.9855 - loss: 0.1767 - val_accuracy: 0.8797 - val_loss: 0.5634 - learning_rate: 4.8828e-07\n",
      "Epoch 116/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.9863 - loss: 0.1787\n",
      "Epoch 116: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 111ms/step - accuracy: 0.9863 - loss: 0.1787 - val_accuracy: 0.8786 - val_loss: 0.5638 - learning_rate: 4.8828e-07\n",
      "Epoch 117/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.9864 - loss: 0.1792\n",
      "Epoch 117: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 111ms/step - accuracy: 0.9864 - loss: 0.1791 - val_accuracy: 0.8790 - val_loss: 0.5624 - learning_rate: 4.8828e-07\n",
      "Epoch 118/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.9850 - loss: 0.1766\n",
      "Epoch 118: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 110ms/step - accuracy: 0.9851 - loss: 0.1766 - val_accuracy: 0.8786 - val_loss: 0.5623 - learning_rate: 4.8828e-07\n",
      "Epoch 119/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9860 - loss: 0.1761\n",
      "Epoch 119: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 106ms/step - accuracy: 0.9860 - loss: 0.1761 - val_accuracy: 0.8776 - val_loss: 0.5639 - learning_rate: 4.8828e-07\n",
      "Epoch 120/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.9838 - loss: 0.1800\n",
      "Epoch 120: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 108ms/step - accuracy: 0.9838 - loss: 0.1800 - val_accuracy: 0.8793 - val_loss: 0.5631 - learning_rate: 4.8828e-07\n",
      "Epoch 121/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.9878 - loss: 0.1735\n",
      "Epoch 121: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 108ms/step - accuracy: 0.9878 - loss: 0.1735 - val_accuracy: 0.8797 - val_loss: 0.5642 - learning_rate: 2.4414e-07\n",
      "Epoch 122/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9880 - loss: 0.1728\n",
      "Epoch 122: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 102ms/step - accuracy: 0.9880 - loss: 0.1728 - val_accuracy: 0.8793 - val_loss: 0.5623 - learning_rate: 2.4414e-07\n",
      "Epoch 123/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.9867 - loss: 0.1734\n",
      "Epoch 123: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 102ms/step - accuracy: 0.9867 - loss: 0.1734 - val_accuracy: 0.8786 - val_loss: 0.5648 - learning_rate: 2.4414e-07\n",
      "Epoch 124/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9862 - loss: 0.1755\n",
      "Epoch 124: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 105ms/step - accuracy: 0.9862 - loss: 0.1755 - val_accuracy: 0.8793 - val_loss: 0.5643 - learning_rate: 2.4414e-07\n",
      "Epoch 125/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9870 - loss: 0.1741\n",
      "Epoch 125: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 103ms/step - accuracy: 0.9870 - loss: 0.1741 - val_accuracy: 0.8797 - val_loss: 0.5650 - learning_rate: 2.4414e-07\n",
      "Epoch 126/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9883 - loss: 0.1737\n",
      "Epoch 126: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 106ms/step - accuracy: 0.9883 - loss: 0.1738 - val_accuracy: 0.8790 - val_loss: 0.5643 - learning_rate: 2.4414e-07\n",
      "Epoch 127/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9895 - loss: 0.1712\n",
      "Epoch 127: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 105ms/step - accuracy: 0.9895 - loss: 0.1712 - val_accuracy: 0.8793 - val_loss: 0.5629 - learning_rate: 2.4414e-07\n",
      "Epoch 128/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9867 - loss: 0.1739\n",
      "Epoch 128: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 103ms/step - accuracy: 0.9867 - loss: 0.1739 - val_accuracy: 0.8786 - val_loss: 0.5629 - learning_rate: 2.4414e-07\n",
      "Epoch 129/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.9877 - loss: 0.1779\n",
      "Epoch 129: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 103ms/step - accuracy: 0.9877 - loss: 0.1779 - val_accuracy: 0.8793 - val_loss: 0.5633 - learning_rate: 2.4414e-07\n",
      "Epoch 130/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9861 - loss: 0.1764\n",
      "Epoch 130: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 103ms/step - accuracy: 0.9861 - loss: 0.1764 - val_accuracy: 0.8786 - val_loss: 0.5627 - learning_rate: 2.4414e-07\n",
      "Epoch 131/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9849 - loss: 0.1790\n",
      "Epoch 131: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 105ms/step - accuracy: 0.9850 - loss: 0.1790 - val_accuracy: 0.8797 - val_loss: 0.5650 - learning_rate: 1.2207e-07\n",
      "Epoch 132/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9876 - loss: 0.1743\n",
      "Epoch 132: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 106ms/step - accuracy: 0.9876 - loss: 0.1743 - val_accuracy: 0.8786 - val_loss: 0.5634 - learning_rate: 1.2207e-07\n",
      "Epoch 133/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9837 - loss: 0.1807\n",
      "Epoch 133: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 104ms/step - accuracy: 0.9837 - loss: 0.1807 - val_accuracy: 0.8790 - val_loss: 0.5644 - learning_rate: 1.2207e-07\n",
      "Epoch 134/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9853 - loss: 0.1750\n",
      "Epoch 134: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 104ms/step - accuracy: 0.9853 - loss: 0.1750 - val_accuracy: 0.8790 - val_loss: 0.5628 - learning_rate: 1.2207e-07\n",
      "Epoch 135/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9847 - loss: 0.1796\n",
      "Epoch 135: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 104ms/step - accuracy: 0.9847 - loss: 0.1796 - val_accuracy: 0.8786 - val_loss: 0.5633 - learning_rate: 1.2207e-07\n",
      "Epoch 136/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.9833 - loss: 0.1772\n",
      "Epoch 136: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 102ms/step - accuracy: 0.9833 - loss: 0.1772 - val_accuracy: 0.8797 - val_loss: 0.5631 - learning_rate: 1.2207e-07\n",
      "Epoch 137/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.9842 - loss: 0.1751\n",
      "Epoch 137: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 106ms/step - accuracy: 0.9842 - loss: 0.1751 - val_accuracy: 0.8793 - val_loss: 0.5632 - learning_rate: 1.2207e-07\n",
      "Epoch 138/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.9882 - loss: 0.1748\n",
      "Epoch 138: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 103ms/step - accuracy: 0.9882 - loss: 0.1748 - val_accuracy: 0.8790 - val_loss: 0.5629 - learning_rate: 1.2207e-07\n",
      "Epoch 139/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.9836 - loss: 0.1790\n",
      "Epoch 139: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 102ms/step - accuracy: 0.9836 - loss: 0.1790 - val_accuracy: 0.8793 - val_loss: 0.5639 - learning_rate: 1.2207e-07\n",
      "Epoch 140/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9876 - loss: 0.1778\n",
      "Epoch 140: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 106ms/step - accuracy: 0.9876 - loss: 0.1778 - val_accuracy: 0.8786 - val_loss: 0.5633 - learning_rate: 1.2207e-07\n",
      "Epoch 141/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.9869 - loss: 0.1731\n",
      "Epoch 141: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 101ms/step - accuracy: 0.9869 - loss: 0.1731 - val_accuracy: 0.8793 - val_loss: 0.5621 - learning_rate: 6.1035e-08\n",
      "Epoch 142/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9859 - loss: 0.1800\n",
      "Epoch 142: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 105ms/step - accuracy: 0.9859 - loss: 0.1800 - val_accuracy: 0.8786 - val_loss: 0.5638 - learning_rate: 6.1035e-08\n",
      "Epoch 143/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9871 - loss: 0.1756\n",
      "Epoch 143: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 107ms/step - accuracy: 0.9871 - loss: 0.1756 - val_accuracy: 0.8776 - val_loss: 0.5646 - learning_rate: 6.1035e-08\n",
      "Epoch 144/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9831 - loss: 0.1801\n",
      "Epoch 144: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 103ms/step - accuracy: 0.9831 - loss: 0.1801 - val_accuracy: 0.8793 - val_loss: 0.5640 - learning_rate: 6.1035e-08\n",
      "Epoch 145/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9858 - loss: 0.1755\n",
      "Epoch 145: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 106ms/step - accuracy: 0.9858 - loss: 0.1755 - val_accuracy: 0.8790 - val_loss: 0.5635 - learning_rate: 6.1035e-08\n",
      "Epoch 146/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.9866 - loss: 0.1745\n",
      "Epoch 146: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 113ms/step - accuracy: 0.9866 - loss: 0.1745 - val_accuracy: 0.8793 - val_loss: 0.5622 - learning_rate: 6.1035e-08\n",
      "Epoch 147/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9870 - loss: 0.1738\n",
      "Epoch 147: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 105ms/step - accuracy: 0.9870 - loss: 0.1738 - val_accuracy: 0.8790 - val_loss: 0.5643 - learning_rate: 6.1035e-08\n",
      "Epoch 148/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9854 - loss: 0.1787\n",
      "Epoch 148: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 107ms/step - accuracy: 0.9854 - loss: 0.1787 - val_accuracy: 0.8790 - val_loss: 0.5631 - learning_rate: 6.1035e-08\n",
      "Epoch 149/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9855 - loss: 0.1776\n",
      "Epoch 149: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 106ms/step - accuracy: 0.9855 - loss: 0.1775 - val_accuracy: 0.8797 - val_loss: 0.5626 - learning_rate: 6.1035e-08\n",
      "Epoch 150/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9896 - loss: 0.1679\n",
      "Epoch 150: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 104ms/step - accuracy: 0.9896 - loss: 0.1679 - val_accuracy: 0.8793 - val_loss: 0.5633 - learning_rate: 6.1035e-08\n",
      "Epoch 151/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9872 - loss: 0.1743\n",
      "Epoch 151: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 107ms/step - accuracy: 0.9871 - loss: 0.1743 - val_accuracy: 0.8779 - val_loss: 0.5644 - learning_rate: 3.0518e-08\n",
      "Epoch 152/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9871 - loss: 0.1717\n",
      "Epoch 152: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 104ms/step - accuracy: 0.9871 - loss: 0.1717 - val_accuracy: 0.8790 - val_loss: 0.5625 - learning_rate: 3.0518e-08\n",
      "Epoch 153/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.9880 - loss: 0.1735\n",
      "Epoch 153: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 108ms/step - accuracy: 0.9880 - loss: 0.1735 - val_accuracy: 0.8797 - val_loss: 0.5634 - learning_rate: 3.0518e-08\n",
      "Epoch 154/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9899 - loss: 0.1687\n",
      "Epoch 154: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 102ms/step - accuracy: 0.9899 - loss: 0.1687 - val_accuracy: 0.8786 - val_loss: 0.5638 - learning_rate: 3.0518e-08\n",
      "Epoch 155/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9846 - loss: 0.1771\n",
      "Epoch 155: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 105ms/step - accuracy: 0.9846 - loss: 0.1771 - val_accuracy: 0.8786 - val_loss: 0.5624 - learning_rate: 3.0518e-08\n",
      "Epoch 156/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9875 - loss: 0.1748\n",
      "Epoch 156: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 106ms/step - accuracy: 0.9874 - loss: 0.1748 - val_accuracy: 0.8793 - val_loss: 0.5630 - learning_rate: 3.0518e-08\n",
      "Epoch 157/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.9872 - loss: 0.1734\n",
      "Epoch 157: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 107ms/step - accuracy: 0.9872 - loss: 0.1734 - val_accuracy: 0.8786 - val_loss: 0.5638 - learning_rate: 3.0518e-08\n",
      "Epoch 158/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.9876 - loss: 0.1747\n",
      "Epoch 158: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 108ms/step - accuracy: 0.9876 - loss: 0.1747 - val_accuracy: 0.8797 - val_loss: 0.5637 - learning_rate: 3.0518e-08\n",
      "Epoch 159/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9835 - loss: 0.1779\n",
      "Epoch 159: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 103ms/step - accuracy: 0.9835 - loss: 0.1779 - val_accuracy: 0.8800 - val_loss: 0.5626 - learning_rate: 3.0518e-08\n",
      "Epoch 160/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9871 - loss: 0.1729\n",
      "Epoch 160: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 104ms/step - accuracy: 0.9871 - loss: 0.1729 - val_accuracy: 0.8783 - val_loss: 0.5632 - learning_rate: 3.0518e-08\n",
      "Epoch 161/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9860 - loss: 0.1761\n",
      "Epoch 161: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 105ms/step - accuracy: 0.9859 - loss: 0.1761 - val_accuracy: 0.8790 - val_loss: 0.5635 - learning_rate: 1.5259e-08\n",
      "Epoch 162/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9854 - loss: 0.1751\n",
      "Epoch 162: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 105ms/step - accuracy: 0.9854 - loss: 0.1751 - val_accuracy: 0.8783 - val_loss: 0.5627 - learning_rate: 1.5259e-08\n",
      "Epoch 163/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9894 - loss: 0.1741\n",
      "Epoch 163: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 105ms/step - accuracy: 0.9894 - loss: 0.1741 - val_accuracy: 0.8776 - val_loss: 0.5625 - learning_rate: 1.5259e-08\n",
      "Epoch 164/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9856 - loss: 0.1764\n",
      "Epoch 164: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 103ms/step - accuracy: 0.9856 - loss: 0.1764 - val_accuracy: 0.8790 - val_loss: 0.5641 - learning_rate: 1.5259e-08\n",
      "Epoch 165/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9858 - loss: 0.1749\n",
      "Epoch 165: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 106ms/step - accuracy: 0.9858 - loss: 0.1749 - val_accuracy: 0.8790 - val_loss: 0.5634 - learning_rate: 1.5259e-08\n",
      "Epoch 166/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9842 - loss: 0.1767\n",
      "Epoch 166: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 106ms/step - accuracy: 0.9842 - loss: 0.1767 - val_accuracy: 0.8793 - val_loss: 0.5631 - learning_rate: 1.5259e-08\n",
      "Epoch 167/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9852 - loss: 0.1780\n",
      "Epoch 167: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 104ms/step - accuracy: 0.9852 - loss: 0.1780 - val_accuracy: 0.8790 - val_loss: 0.5639 - learning_rate: 1.5259e-08\n",
      "Epoch 168/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9877 - loss: 0.1737\n",
      "Epoch 168: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 104ms/step - accuracy: 0.9877 - loss: 0.1737 - val_accuracy: 0.8793 - val_loss: 0.5624 - learning_rate: 1.5259e-08\n",
      "Epoch 169/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.9859 - loss: 0.1695\n",
      "Epoch 169: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 102ms/step - accuracy: 0.9859 - loss: 0.1695 - val_accuracy: 0.8790 - val_loss: 0.5622 - learning_rate: 1.5259e-08\n",
      "Epoch 170/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9837 - loss: 0.1774\n",
      "Epoch 170: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 104ms/step - accuracy: 0.9837 - loss: 0.1774 - val_accuracy: 0.8786 - val_loss: 0.5640 - learning_rate: 1.5259e-08\n",
      "Epoch 171/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9878 - loss: 0.1729\n",
      "Epoch 171: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 104ms/step - accuracy: 0.9878 - loss: 0.1729 - val_accuracy: 0.8779 - val_loss: 0.5636 - learning_rate: 7.6294e-09\n",
      "Epoch 172/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.9837 - loss: 0.1762\n",
      "Epoch 172: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 102ms/step - accuracy: 0.9837 - loss: 0.1762 - val_accuracy: 0.8779 - val_loss: 0.5634 - learning_rate: 7.6294e-09\n",
      "Epoch 173/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9851 - loss: 0.1752\n",
      "Epoch 173: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 105ms/step - accuracy: 0.9851 - loss: 0.1752 - val_accuracy: 0.8786 - val_loss: 0.5635 - learning_rate: 7.6294e-09\n",
      "Epoch 174/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9870 - loss: 0.1743\n",
      "Epoch 174: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 107ms/step - accuracy: 0.9870 - loss: 0.1743 - val_accuracy: 0.8793 - val_loss: 0.5631 - learning_rate: 7.6294e-09\n",
      "Epoch 175/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.9876 - loss: 0.1720\n",
      "Epoch 175: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 102ms/step - accuracy: 0.9876 - loss: 0.1719 - val_accuracy: 0.8790 - val_loss: 0.5637 - learning_rate: 7.6294e-09\n",
      "Epoch 176/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9867 - loss: 0.1718\n",
      "Epoch 176: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 106ms/step - accuracy: 0.9867 - loss: 0.1718 - val_accuracy: 0.8790 - val_loss: 0.5633 - learning_rate: 7.6294e-09\n",
      "Epoch 177/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.9845 - loss: 0.1821\n",
      "Epoch 177: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 107ms/step - accuracy: 0.9845 - loss: 0.1821 - val_accuracy: 0.8790 - val_loss: 0.5632 - learning_rate: 7.6294e-09\n",
      "Epoch 178/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9859 - loss: 0.1733\n",
      "Epoch 178: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 105ms/step - accuracy: 0.9859 - loss: 0.1733 - val_accuracy: 0.8790 - val_loss: 0.5643 - learning_rate: 7.6294e-09\n",
      "Epoch 179/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9850 - loss: 0.1779\n",
      "Epoch 179: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 103ms/step - accuracy: 0.9850 - loss: 0.1779 - val_accuracy: 0.8779 - val_loss: 0.5627 - learning_rate: 7.6294e-09\n",
      "Epoch 180/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.9881 - loss: 0.1724\n",
      "Epoch 180: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 102ms/step - accuracy: 0.9881 - loss: 0.1724 - val_accuracy: 0.8786 - val_loss: 0.5642 - learning_rate: 7.6294e-09\n",
      "Epoch 181/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9846 - loss: 0.1790\n",
      "Epoch 181: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 104ms/step - accuracy: 0.9846 - loss: 0.1790 - val_accuracy: 0.8793 - val_loss: 0.5630 - learning_rate: 3.8147e-09\n",
      "Epoch 182/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9879 - loss: 0.1743\n",
      "Epoch 182: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 104ms/step - accuracy: 0.9879 - loss: 0.1744 - val_accuracy: 0.8793 - val_loss: 0.5641 - learning_rate: 3.8147e-09\n",
      "Epoch 183/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9863 - loss: 0.1741\n",
      "Epoch 183: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 107ms/step - accuracy: 0.9863 - loss: 0.1741 - val_accuracy: 0.8793 - val_loss: 0.5643 - learning_rate: 3.8147e-09\n",
      "Epoch 184/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9877 - loss: 0.1740\n",
      "Epoch 184: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 104ms/step - accuracy: 0.9877 - loss: 0.1740 - val_accuracy: 0.8793 - val_loss: 0.5634 - learning_rate: 3.8147e-09\n",
      "Epoch 185/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9829 - loss: 0.1775\n",
      "Epoch 185: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 106ms/step - accuracy: 0.9829 - loss: 0.1775 - val_accuracy: 0.8790 - val_loss: 0.5641 - learning_rate: 3.8147e-09\n",
      "Epoch 186/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9855 - loss: 0.1730\n",
      "Epoch 186: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 107ms/step - accuracy: 0.9855 - loss: 0.1730 - val_accuracy: 0.8793 - val_loss: 0.5640 - learning_rate: 3.8147e-09\n",
      "Epoch 187/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9855 - loss: 0.1761\n",
      "Epoch 187: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 104ms/step - accuracy: 0.9855 - loss: 0.1761 - val_accuracy: 0.8783 - val_loss: 0.5624 - learning_rate: 3.8147e-09\n",
      "Epoch 188/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.9895 - loss: 0.1702\n",
      "Epoch 188: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 102ms/step - accuracy: 0.9895 - loss: 0.1702 - val_accuracy: 0.8783 - val_loss: 0.5626 - learning_rate: 3.8147e-09\n",
      "Epoch 189/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9860 - loss: 0.1752\n",
      "Epoch 189: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 105ms/step - accuracy: 0.9860 - loss: 0.1752 - val_accuracy: 0.8786 - val_loss: 0.5630 - learning_rate: 3.8147e-09\n",
      "Epoch 190/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.9885 - loss: 0.1721\n",
      "Epoch 190: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 112ms/step - accuracy: 0.9885 - loss: 0.1721 - val_accuracy: 0.8783 - val_loss: 0.5632 - learning_rate: 3.8147e-09\n",
      "Epoch 191/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.9864 - loss: 0.1732\n",
      "Epoch 191: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 119ms/step - accuracy: 0.9864 - loss: 0.1731 - val_accuracy: 0.8786 - val_loss: 0.5632 - learning_rate: 1.9073e-09\n",
      "Epoch 192/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.9863 - loss: 0.1766\n",
      "Epoch 192: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 116ms/step - accuracy: 0.9863 - loss: 0.1766 - val_accuracy: 0.8790 - val_loss: 0.5622 - learning_rate: 1.9073e-09\n",
      "Epoch 193/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.9850 - loss: 0.1741\n",
      "Epoch 193: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 120ms/step - accuracy: 0.9850 - loss: 0.1741 - val_accuracy: 0.8800 - val_loss: 0.5628 - learning_rate: 1.9073e-09\n",
      "Epoch 194/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.9855 - loss: 0.1808\n",
      "Epoch 194: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 118ms/step - accuracy: 0.9855 - loss: 0.1807 - val_accuracy: 0.8783 - val_loss: 0.5627 - learning_rate: 1.9073e-09\n",
      "Epoch 195/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.9880 - loss: 0.1723\n",
      "Epoch 195: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 114ms/step - accuracy: 0.9880 - loss: 0.1723 - val_accuracy: 0.8793 - val_loss: 0.5633 - learning_rate: 1.9073e-09\n",
      "Epoch 196/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.9901 - loss: 0.1689\n",
      "Epoch 196: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 113ms/step - accuracy: 0.9900 - loss: 0.1690 - val_accuracy: 0.8793 - val_loss: 0.5638 - learning_rate: 1.9073e-09\n",
      "Epoch 197/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.9849 - loss: 0.1760\n",
      "Epoch 197: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 112ms/step - accuracy: 0.9849 - loss: 0.1760 - val_accuracy: 0.8797 - val_loss: 0.5635 - learning_rate: 1.9073e-09\n",
      "Epoch 198/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.9848 - loss: 0.1774\n",
      "Epoch 198: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 110ms/step - accuracy: 0.9848 - loss: 0.1774 - val_accuracy: 0.8800 - val_loss: 0.5638 - learning_rate: 1.9073e-09\n",
      "Epoch 199/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.9867 - loss: 0.1753\n",
      "Epoch 199: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 107ms/step - accuracy: 0.9866 - loss: 0.1754 - val_accuracy: 0.8779 - val_loss: 0.5639 - learning_rate: 1.9073e-09\n",
      "Epoch 200/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9832 - loss: 0.1809\n",
      "Epoch 200: val_accuracy did not improve from 0.88215\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 107ms/step - accuracy: 0.9832 - loss: 0.1809 - val_accuracy: 0.8797 - val_loss: 0.5633 - learning_rate: 1.9073e-09\n"
     ]
    }
   ],
   "source": [
    "modelCustom = CustomCNN()\n",
    "\n",
    "modelCustom.compile(optimizer=optimizer,\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    '5kelasterbaek.keras',                  # Nama file untuk menyimpan model\n",
    "    monitor='val_accuracy',           # Memantau akurasi validasi\n",
    "    save_best_only=True,               # Hanya menyimpan model dengan performa terbaik\n",
    "    mode='max',                        # Mode 'max' berarti model dengan nilai tertinggi yang akan disimpan\n",
    "    verbose=1                          # Menampilkan status setiap kali model disimpan\n",
    ")\n",
    "\n",
    "history = modelCustom.fit(train_generator,\n",
    "                          # steps_per_epoch=train_generator.samples // batch_size,\n",
    "                          epochs=200,\n",
    "                          validation_data=test_generator,\n",
    "                          # validation_steps=test_generator.samples // batch_size, \n",
    "                          callbacks=[lr_callback,checkpoint]  # Use the lr_callback here\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sanju\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - accuracy: 0.8900 - loss: 0.5429\n",
      "Test accuracy: 0.88, test loss: 0.57\n"
     ]
    }
   ],
   "source": [
    "modelCustom = load_model(\"../model/5kelas.keras\")\n",
    "test_loss, test_acc = modelCustom.evaluate(test_generator)\n",
    "print(f\"Test accuracy: {test_acc:.2f}, test loss: {test_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Confusion Matrix & Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.88      0.77      0.82       162\n",
      "       happy       0.94      0.94      0.94      1185\n",
      "     neutral       0.82      0.86      0.84       680\n",
      "         sad       0.84      0.82      0.83       478\n",
      "   surprised       0.89      0.84      0.86       329\n",
      "\n",
      "    accuracy                           0.88      2834\n",
      "   macro avg       0.87      0.85      0.86      2834\n",
      "weighted avg       0.88      0.88      0.88      2834\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_names = ['angry', 'happy', 'neutral', 'sad', 'surprised']\n",
    "# Mendapatkan prediksi dari generator validasi\n",
    "y_true = test_generator.classes  # Label asli\n",
    "y_pred = modelCustom.predict(test_generator)  # Probabilitas prediksi\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # Kelas prediksi\n",
    "\n",
    "# Menampilkan confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred_classes)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Menampilkan laporan klasifikasi\n",
    "report = classification_report(y_true, y_pred_classes, target_names=class_names)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 786787,
     "sourceId": 1351797,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3758654,
     "sourceId": 6504606,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6189487,
     "sourceId": 10046625,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6189868,
     "sourceId": 10047135,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
